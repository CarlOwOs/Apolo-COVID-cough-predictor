{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elias/anaconda3/lib/python3.7/site-packages/torchaudio/backend/utils.py:54: UserWarning: \"sox\" backend is being deprecated. The default backend will be changed to \"sox_io\" backend in 0.8.0 and \"sox\" backend will be removed in 0.9.0. Please migrate to \"sox_io\" backend. Please refer to https://github.com/pytorch/audio/issues/903 for the detail.\n",
      "  '\"sox\" backend is being deprecated. '\n",
      "/home/elias/anaconda3/lib/python3.7/site-packages/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  /pytorch/c10/cuda/CUDAFunctions.cpp:100.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchaudio\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "device = 'cpu'\n",
    "if torch.cuda.is_available():\n",
    "  device = 'cuda'\n",
    "  torch.cuda.manual_seed_all(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir specgrams\n",
    "!mkdir specgrams/TRAIN\n",
    "!mkdir specgrams/TRAIN/Cough\n",
    "!mkdir specgrams/TRAIN/No_Cough\n",
    "!mkdir specgrams/TEST\n",
    "!mkdir specgrams/TEST/Cough\n",
    "!mkdir specgrams/TEST/No_Cough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wave_to_specgram(folder_path):    \n",
    "    file_list = os.listdir(folder_path)\n",
    "    dataset = torch.empty(1)\n",
    "    for file in file_list:\n",
    "        if file != '.DS_Store':\n",
    "            waveform, sample_rate = torchaudio.load(folder_path+'/'+file)\n",
    "            specgram = torchaudio.transforms.Spectrogram()(waveform)\n",
    "            specgram_resize = torchvision.transforms.Resize((224,224))(specgram)\n",
    "            plt.figure(frameon=False)\n",
    "            plt.axis('off')\n",
    "            plt.imshow(specgram_resize.log2()[0,:,:].numpy(), cmap='gray')\n",
    "            plt.savefig('./specgrams/'+folder_path.split('/')[-2]+'/'+folder_path.split('/')[-1]+'/'+file.strip('.wav')+'.png')\n",
    "            plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elias/anaconda3/lib/python3.7/site-packages/torch/functional.py:516: UserWarning: stft will require the return_complex parameter be explicitly  specified in a future PyTorch release. Use return_complex=False  to preserve the current behavior or return_complex=True to return  a complex output. (Triggered internally at  /pytorch/aten/src/ATen/native/SpectralOps.cpp:653.)\n",
      "  normalized, onesided, return_complex)\n",
      "/home/elias/anaconda3/lib/python3.7/site-packages/torch/functional.py:516: UserWarning: The function torch.rfft is deprecated and will be removed in a future PyTorch release. Use the new torch.fft module functions, instead, by importing torch.fft and calling torch.fft.fft or torch.fft.rfft. (Triggered internally at  /pytorch/aten/src/ATen/native/SpectralOps.cpp:590.)\n",
      "  normalized, onesided, return_complex)\n",
      "/home/elias/anaconda3/lib/python3.7/site-packages/matplotlib/image.py:405: UserWarning: Warning: converting a masked element to nan.\n",
      "  dv = (np.float64(self.norm.vmax) -\n",
      "/home/elias/anaconda3/lib/python3.7/site-packages/matplotlib/image.py:406: UserWarning: Warning: converting a masked element to nan.\n",
      "  np.float64(self.norm.vmin))\n",
      "/home/elias/anaconda3/lib/python3.7/site-packages/matplotlib/image.py:413: UserWarning: Warning: converting a masked element to nan.\n",
      "  a_min = np.float64(newmin)\n",
      "/home/elias/anaconda3/lib/python3.7/site-packages/matplotlib/image.py:418: UserWarning: Warning: converting a masked element to nan.\n",
      "  a_max = np.float64(newmax)\n",
      "/home/elias/anaconda3/lib/python3.7/site-packages/matplotlib/colors.py:916: UserWarning: Warning: converting a masked element to nan.\n",
      "  dtype = np.min_scalar_type(value)\n",
      "/home/elias/anaconda3/lib/python3.7/site-packages/numpy/ma/core.py:715: UserWarning: Warning: converting a masked element to nan.\n",
      "  data = np.array(a, copy=False, subok=subok)\n"
     ]
    }
   ],
   "source": [
    "train_cough_dir = './Cough_dataset/Unlabeled_audio/TRAIN/Cough'\n",
    "train_nocough_dir = './Cough_dataset/Unlabeled_audio/TRAIN/No_Cough'\n",
    "test_cough_dir = './Cough_dataset/Unlabeled_audio/TEST/Cough'\n",
    "test_nocough_dir = './Cough_dataset/Unlabeled_audio/TEST/No_Cough'\n",
    "\n",
    "wave_to_specgram(train_cough_dir)\n",
    "wave_to_specgram(train_nocough_dir)\n",
    "wave_to_specgram(test_cough_dir)\n",
    "wave_to_specgram(test_nocough_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total training cough files: 359\n",
      "total training nocough files: 301\n",
      "total validation cough files: 155\n",
      "total validation nocough files: 130\n"
     ]
    }
   ],
   "source": [
    "train_cough_dir = './Cough_dataset/Unlabeled_audio/TRAIN/Cough'\n",
    "train_nocough_dir = './Cough_dataset/Unlabeled_audio/TRAIN/No_Cough'\n",
    "test_cough_dir = './Cough_dataset/Unlabeled_audio/TEST/Cough'\n",
    "test_nocough_dir = './Cough_dataset/Unlabeled_audio/TEST/No_Cough'\n",
    "print('total training cough files:', len(os.listdir(train_cough_dir)))\n",
    "print('total training nocough files:', len(os.listdir(train_nocough_dir)))\n",
    "print('total validation cough files:', len(os.listdir(test_cough_dir)))\n",
    "print('total validation nocough files:', len(os.listdir(test_nocough_dir)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_dataset = ImageFolder(train_dir, transform=transform)\n",
    "#train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "#val_dataset = ImageFolder(validation_dir, transform=transform)\n",
    "#val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "## test git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (1): ReLU()\n",
       "  (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (4): ReLU()\n",
       "  (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (6): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (7): ReLU()\n",
       "  (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (9): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (10): ReLU()\n",
       "  (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (12): Flatten(start_dim=1, end_dim=-1)\n",
       "  (13): Linear(in_features=12544, out_features=512, bias=True)\n",
       "  (14): ReLU()\n",
       "  (15): Linear(in_features=512, out_features=1, bias=True)\n",
       "  (16): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Conv2d(3, 64, 3),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(2),\n",
    "    nn.Conv2d(64, 128, 3),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(2),\n",
    "    nn.Conv2d(128, 256, 3),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(2),\n",
    "    nn.Conv2d(256, 256, 3),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(2),\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(256*7*7, 512),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(512, 1),\n",
    "    nn.Sigmoid()\n",
    ")\n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "loss_fn = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
