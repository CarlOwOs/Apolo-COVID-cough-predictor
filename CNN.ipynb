{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Carlos/Documents/Anaconda/anaconda3/lib/python3.6/site-packages/torchaudio/backend/utils.py:54: UserWarning: \"sox\" backend is being deprecated. The default backend will be changed to \"sox_io\" backend in 0.8.0 and \"sox\" backend will be removed in 0.9.0. Please migrate to \"sox_io\" backend. Please refer to https://github.com/pytorch/audio/issues/903 for the detail.\n",
      "  '\"sox\" backend is being deprecated. '\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchaudio\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "device = 'cpu'\n",
    "if torch.cuda.is_available():\n",
    "  device = 'cuda'\n",
    "  torch.cuda.manual_seed_all(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir specgrams\n",
    "!mkdir specgrams/TRAIN\n",
    "!mkdir specgrams/TRAIN/Cough\n",
    "!mkdir specgrams/TRAIN/No_Cough\n",
    "!mkdir specgrams/TEST\n",
    "!mkdir specgrams/TEST/Cough\n",
    "!mkdir specgrams/TEST/No_Cough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wave_to_specgram(folder_path):    \n",
    "    file_list = os.listdir(folder_path)\n",
    "    dataset = torch.empty(1)\n",
    "    for file in file_list:\n",
    "        if file != '.DS_Store':\n",
    "            waveform, sample_rate = torchaudio.load(folder_path+'/'+file)\n",
    "            specgram = torchaudio.transforms.Spectrogram()(waveform)\n",
    "            specgram_resize = torchvision.transforms.Resize((224,224))(specgram)\n",
    "            plt.figure(frameon=False)\n",
    "            plt.axis('off')\n",
    "            plt.imshow(specgram_resize.log2()[0,:,:].numpy(), cmap='gray')\n",
    "            plt.savefig('./specgrams/'+folder_path.split('/')[-2]+'/'+folder_path.split('/')[-1]+'/'+file.strip('.wav')+'.png')\n",
    "            plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cough_dir = './Cough_dataset/Unlabeled_audio/TRAIN/Cough'\n",
    "train_nocough_dir = './Cough_dataset/Unlabeled_audio/TRAIN/No_Cough'\n",
    "test_cough_dir = './Cough_dataset/Unlabeled_audio/TEST/Cough'\n",
    "test_nocough_dir = './Cough_dataset/Unlabeled_audio/TEST/No_Cough'\n",
    "\n",
    "wave_to_specgram(train_cough_dir)\n",
    "wave_to_specgram(train_nocough_dir)\n",
    "wave_to_specgram(test_cough_dir)\n",
    "wave_to_specgram(test_nocough_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total training cough files: 360\n",
      "total training nocough files: 302\n",
      "total validation cough files: 155\n",
      "total validation nocough files: 130\n"
     ]
    }
   ],
   "source": [
    "print('total training cough files:', len(os.listdir(train_cough_dir)))\n",
    "print('total training nocough files:', len(os.listdir(train_nocough_dir)))\n",
    "print('total validation cough files:', len(os.listdir(test_cough_dir)))\n",
    "print('total validation nocough files:', len(os.listdir(test_nocough_dir)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = './specgrams/TRAIN'\n",
    "test_dir = './specgrams/TEST'\n",
    "transform = torchvision.transforms.Compose([torchvision.transforms.ToTensor()])\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "train_dataset = torchvision.datasets.ImageFolder(train_dir, transform=transform)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "#val_dataset = ImageFolder(validation_dir, transform=transform)\n",
    "#val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "## test git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (1): ReLU()\n",
       "  (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (4): ReLU()\n",
       "  (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (6): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (7): ReLU()\n",
       "  (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (9): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (10): ReLU()\n",
       "  (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (12): Flatten(start_dim=1, end_dim=-1)\n",
       "  (13): Linear(in_features=12544, out_features=512, bias=True)\n",
       "  (14): ReLU()\n",
       "  (15): Linear(in_features=512, out_features=1, bias=True)\n",
       "  (16): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Conv2d(3, 64, 3),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(2),\n",
    "    nn.Conv2d(64, 128, 3),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(2),\n",
    "    nn.Conv2d(128, 256, 3),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(2),\n",
    "    nn.Conv2d(256, 256, 3),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(2),\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(256*7*7, 512),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(512, 1),\n",
    "    nn.Sigmoid()\n",
    ")\n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "loss_fn = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
